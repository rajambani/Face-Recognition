{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# MODEL\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.read_csv(\"data/X.csv\", sep=' ', header=None, dtype=float)\n",
    "X=x.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.read_csv(\"data/y_bush_vs_others.csv\", sep=' ', header=None)\n",
    "y_bush = y.values.ravel()\n",
    "y = pd.read_csv(\"data/y_williams_vs_others.csv\", sep=' ', header=None)\n",
    "y_williams = y.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13233, 4096)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#phase 3\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Reshape\n",
    "X = np.array(X).reshape(13233,64,64,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #check\n",
    "\n",
    "# model=Sequential()\n",
    "# model.add(Conv2D(32, kernel_size=(5,5),input_shape=(64,64,1),activation='relu'))\n",
    "# model.add(MaxPooling2D(strides=(2,2)))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dropout(0.05))\n",
    "# model.add(Dense(1,activation='sigmoid'))\n",
    "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# model.fit(x_train_bush, y_train_bush, validation_data=(x_test_bush, y_test_bush), epochs=10)\n",
    "# pred_train=np.round(model.predict(x_train_bush))\n",
    "# pred_test=np.round(model.predict(x_test_bush))\n",
    "# print('Train F1 Score ', f1_score(y_train_bush, pred_train))\n",
    "# print('Test F1 Score ', f1_score(y_test_bush, pred_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Train F1 Score ', f1_score(y_train_bush, pred_train, average='macro'))\n",
    "# print('Test F1 Score ', f1_score(y_test_bush, pred_test,  average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bush_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# bush_model.add(Conv2D(32, kernel_size=(7,7), activation='relu'))\n",
    "# bush_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# bush_model.add(Conv2D(64, kernel_size=(7,7) ,activation='relu'))\n",
    "# bush_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# # the model so far outputs 3D feature maps (height, width, features)\n",
    "\n",
    "# bush_model.add(Flatten()) # this converts our 3D feature maps to 1D feature vectors\n",
    "# bush_model.add(Dense(64, activation='relu'))\n",
    "\n",
    "# bush_model.add(Dropout(0.5))\n",
    "# bush_model.add(Dense(1), activation = 'sigmoid')\n",
    "\n",
    "# bush_model.add(Conv2D(32, kernel_size=(7,7),activation='relu', input_shape=(64,64,1)))\n",
    "# bush_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# bush_model.add(Conv2D(32, kernel_size=(7,7), activation='relu'))\n",
    "# bush_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# bush_model.add(Conv2D(64, kernel_size=(7,7) ,activation='relu'))\n",
    "# bush_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# # the model so far outputs 3D feature maps (height, width, features)\n",
    "\n",
    "# bush_model.add(Flatten()) # this converts our 3D feature maps to 1D feature vectors\n",
    "# bush_model.add(Dense(64, activation='relu'))\n",
    "\n",
    "# bush_model.add(Dropout(0.5))\n",
    "# bush_model.add(Dense(1), activation = 'sigmoid')\n",
    "\n",
    "#bush_model.add(Dense(num_classes, activation='softmax')) #output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_bush, x_test_bush, y_train_bush, y_test_bush = train_test_split(X, y_bush, test_size=1./3,random_state = 6925,\n",
    "                                                                        shuffle = True, stratify = y_bush)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bush phase 4\n",
    "# x_train_bush, x_test_bush, y_train_bush, y_test_bush = train_test_split(X, y_bush, test_size=1./3,random_state = 6925,\n",
    "#                                                                         shuffle = True, stratify = y_bush)\n",
    "\n",
    "bush_model = Sequential()\n",
    "\n",
    "bush_model.add(Conv2D(32, kernel_size=(5,5),input_shape=(64,64,1),activation='relu'))\n",
    "bush_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "bush_model.add(Flatten())\n",
    "bush_model.add(Dropout(0.05))\n",
    "bush_model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "bush_model.compile(loss = 'binary_crossentropy', optimizer = 'rmsprop',\n",
    "                   metrics = ['accuracy'])\n",
    "\n",
    "epochs = 10\n",
    "verbose = 1\n",
    "\n",
    "#for i in range():\n",
    "train_bush_model = bush_model.fit(x_train_bush, y_train_bush,epochs=epochs,verbose=verbose,\n",
    "                                  validation_data=(x_test_bush, y_test_bush))\n",
    "#Save model\n",
    "bush_model.save(\"bush.model\")\n",
    "\n",
    "#predicted_classes_bush = bush_model.predict(x_test_bush)\n",
    "#predicted_classes = np.argmax(np.round(predicted_classes_bush),axis=1)\n",
    "\n",
    "y_predict_train_bush = bush_model.predict_classes(x_train_bush)\n",
    "y_predict_test_bush = bush_model.predict_classes(x_test_bush)\n",
    "\n",
    "\n",
    "#print('i: ', i)\n",
    "f1_score_train_bush = f1_score(y_train_bush, y_predict_train_bush)\n",
    "f1_score_test_bush = f1_score(y_test_bush, y_predict_test_bush)\n",
    "\n",
    "print(\"f1_score_train_bush: \", f1_score_train_bush)\n",
    "print(\"f1_score_test_bush: \", f1_score_test_bush)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bush_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ[\"PATH\"] += os.pathsep + 'C:\\Users\\Raj Ambani\\Downloads\\graphviz-2.38\\release\\bin'\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "plot_model(bush_model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_williams, x_test_williams, y_train_williams, y_test_williams = train_test_split(X, y_williams, test_size=1./3,\n",
    "                                                                                        random_state = 6925, shuffle = True, \n",
    "                                                                                        stratify = y_williams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Williams\n",
    "\n",
    "# x_train_williams, x_test_williams, y_train_williams, y_test_williams = train_test_split(X, y_williams, test_size=1./3,\n",
    "#                                                                                         random_state = 6925, shuffle = True, \n",
    "#                                                                                         stratify = y_williams)\n",
    "\n",
    "williams_model = Sequential()\n",
    "\n",
    "williams_model.add(Conv2D(32, kernel_size=(5,5),input_shape=(64,64,1),activation='relu'))\n",
    "williams_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "williams_model.add(Flatten())\n",
    "williams_model.add(Dropout(0.05))\n",
    "williams_model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "williams_model.compile(loss = 'binary_crossentropy', optimizer = 'rmsprop',\n",
    "                   metrics = ['accuracy'])\n",
    "\n",
    "epochs = 8\n",
    "verbose = 1\n",
    "\n",
    "#for i in range(8,16):\n",
    "train_williams_model = williams_model.fit(x_train_williams, y_train_williams,epochs=epochs,verbose=verbose,\n",
    "                                          validation_data=(x_test_williams, y_test_williams))\n",
    "\n",
    "#Save model\n",
    "williams_model.save(\"williams.model\")\n",
    "\n",
    "y_predict_train_williams = williams_model.predict_classes(x_train_williams)\n",
    "y_predict_test_williams = williams_model.predict_classes(x_test_williams)\n",
    "\n",
    "#print('i: ', i)\n",
    "f1_score_train_williams = f1_score(y_train_williams, y_predict_train_williams)\n",
    "f1_score_test_williams = f1_score(y_test_williams, y_predict_test_williams)\n",
    "\n",
    "print(\"f1_score_train_williams: \", f1_score_train_williams)\n",
    "print(\"f1_score_test_williams: \", f1_score_test_williams)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "williams_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pickle Bush \n",
    "\n",
    "import pickle\n",
    "\n",
    "bush = list()\n",
    "bush.append(f1_score_train_bush)\n",
    "bush.append(f1_score_test_bush)\n",
    "pickle.dump((bush), open('bush.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pickle\n",
    "\n",
    "williams = list()\n",
    "williams.append(f1_score_train_williams)\n",
    "williams.append(f1_score_test_williams)\n",
    "\n",
    "pickle.dump((williams), open('williams.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9800000000000001, 0.7761194029850746]\n",
      "[0.8923076923076922, 0.7096774193548386]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "xs = pickle.load(open('bush.pkl', 'rb'))\n",
    "print(xs)\n",
    "\n",
    "xs = pickle.load(open('williams.pkl', 'rb'))\n",
    "print(xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score_train_bush:  0.9800000000000001\n",
      "f1_score_test_bush:  0.7761194029850746\n",
      "f1_score_train_williams:  0.8923076923076922\n",
      "f1_score_test_williams:  0.7096774193548386\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "w = load_model(\"bush.model\")\n",
    "\n",
    "y_predict_train_bush = w.predict_classes(x_train_bush)\n",
    "y_predict_test_bush = w.predict_classes(x_test_bush)\n",
    "\n",
    "f1_score_train_bush = f1_score(y_train_bush, y_predict_train_bush)\n",
    "f1_score_test_bush = f1_score(y_test_bush, y_predict_test_bush)\n",
    "    \n",
    "print(\"f1_score_train_bush: \", f1_score_train_bush)\n",
    "print(\"f1_score_test_bush: \", f1_score_test_bush)\n",
    "\n",
    "w = load_model(\"williams.model\")\n",
    "\n",
    "y_predict_train_bush = w.predict_classes(x_train_williams)\n",
    "y_predict_test_bush = w.predict_classes(x_test_williams)\n",
    "\n",
    "f1_score_train_bush = f1_score(y_train_williams, y_predict_train_bush)\n",
    "f1_score_test_bush = f1_score(y_test_williams, y_predict_test_bush)\n",
    "    \n",
    "print(\"f1_score_train_williams: \", f1_score_train_bush)\n",
    "print(\"f1_score_test_williams: \", f1_score_test_bush)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predicted_classes_bush' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-110-1215334c24d4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtarget_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"Class {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredicted_classes_bush\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test_bush\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpredicted_classes_bush\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtarget_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'predicted_classes_bush' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "target_names = [\"Class {}\".format(i) for i in range(len(predicted_classes_bush))]\n",
    "print(classification_report(y_test_bush,predicted_classes_bush, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#score = bush_model.evaluate(y_train_bush, y_predict_train_bush, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = AccuracyHistory()\n",
    "\n",
    "plt.plot(range(1,11), history.acc)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = fashion_train.history['acc']\n",
    "val_accuracy = fashion_train.history['val_acc']\n",
    "loss = fashion_train.history['loss']\n",
    "val_loss = fashion_train.history['val_loss']\n",
    "epochs = range(len(accuracy))\n",
    "plt.plot(epochs, accuracy, 'bo', label='Training accuracy')\n",
    "plt.plot(epochs, val_accuracy, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #PCA\n",
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "# pca = PCA(n_components=2)\n",
    "# pca.fit(X)\n",
    "# print(pca.explained_variance_ratio_)\n",
    "# print(pca.singular_values_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For Bush knn\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=64)\n",
    "x_pca = pca.fit_transform(X)\n",
    "\n",
    "#neighbors = [1,3,5]\n",
    "neighbors = [1]\n",
    "fit_time_bush = np.zeros((3,1))\n",
    "score_time_bush = np.zeros((3,1))\n",
    "test_f1_bush = np.zeros((3,1))\n",
    "test_precision_bush = np.zeros((3,1))\n",
    "test_recall_bush = np.zeros((3,1))\n",
    "j = 0\n",
    "\n",
    "for currentNeighbors in neighbors:\n",
    "    #print (currentNeighbors)\n",
    "    knn = KNeighborsClassifier(n_neighbors=currentNeighbors)\n",
    "    knn_cv_result = cross_validate(knn, x_pca, y_bush, cv = StratifiedKFold(n_splits = 3, shuffle = True, random_state = 6925), \n",
    "                                    scoring=('precision', 'recall', 'f1'), return_train_score = False, n_jobs = -1)\n",
    "    print(\"j\", j, \"currentNeighbor\", currentNeighbors)\n",
    "    #print(knn_cv_result)\n",
    "    fit_time_bush[j][0] = np.mean(knn_cv_result['fit_time'])\n",
    "    score_time_bush[j][0] = np.mean(knn_cv_result['score_time'])\n",
    "    test_f1_bush[j][0] = np.mean(knn_cv_result['test_f1'])\n",
    "    test_precision_bush[j][0] = np.mean(knn_cv_result['test_precision'])\n",
    "    test_recall_bush[j][0] = np.mean(knn_cv_result['test_recall'])\n",
    "    \n",
    "    j = j+1\n",
    "\n",
    "print(\"test_f1_bush\", test_f1_bush)\n",
    "print(knn_cv_result['test_f1'])\n",
    "print(\"knn_cv_result\", knn_cv_result)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For Williams knn\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=170)\n",
    "x_pca_williams = pca.fit_transform(X)\n",
    "\n",
    "neighbors = [1]\n",
    "fit_time_williams = np.zeros((3,1))\n",
    "score_time_williams = np.zeros((3,1))\n",
    "test_f1_williams = np.zeros((3,1))\n",
    "test_precision_williams = np.zeros((3,1))\n",
    "test_recall_williams = np.zeros((3,1))\n",
    "j = 0\n",
    "\n",
    "for currentNeighbors in neighbors:\n",
    "    #print (currentNeighbors)\n",
    "    knn = KNeighborsClassifier(n_neighbors=currentNeighbors)\n",
    "    knn_cv_result_williams = cross_validate(knn, x_pca_williams, y_williams, cv = StratifiedKFold(n_splits = 3, shuffle = True, random_state = 6925), \n",
    "                                    scoring=('precision', 'recall', 'f1'), return_train_score = False, n_jobs = -1)\n",
    "    print(\"j\", j, \"currentNeighbor\", currentNeighbors)\n",
    "    print(knn_cv_result_williams)\n",
    "    fit_time_williams[j][0] = np.mean(knn_cv_result_williams['fit_time'])\n",
    "    score_time_williams[j][0] = np.mean(knn_cv_result_williams['score_time'])\n",
    "    test_f1_williams[j][0] = np.mean(knn_cv_result_williams['test_f1'])\n",
    "    test_precision_williams[j][0] = np.mean(knn_cv_result_williams['test_precision'])\n",
    "    test_recall_williams[j][0] = np.mean(knn_cv_result_williams['test_recall'])\n",
    "    j = j+1\n",
    "\n",
    "print(knn_cv_result_williams['test_f1'])\n",
    "print(\"mean: \", test_f1_williams)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(knn_cv_result_williams['test_f1'])\n",
    "print(\"mean: \", test_f1_williams)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVC for Bush\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=3000, random_state = 6925)\n",
    "x_pca_svc_bush = pca.fit_transform(X)\n",
    "\n",
    "\n",
    "#C 1000 gamma 0.001,0.01,0.1\n",
    "svc_fit_time_bush = np.zeros((1,1))\n",
    "svc_score_time_bush = np.zeros((1,1))\n",
    "svc_test_f1_bush = np.zeros((1,1))\n",
    "svc_test_precision_bush = np.zeros((1,1))\n",
    "svc_test_recall_bush = np.zeros((1,1))\n",
    "j = 0\n",
    "\n",
    "svc = SVC(C = 1000, kernel = 'poly', degree = 15,gamma = 0.001,  coef0 = 200)\n",
    "#svc = SVC(C = 1000000, kernel = 'linear')\n",
    "svc_cv_result = cross_validate(svc, x_pca_svc_bush, y_bush, cv = StratifiedKFold(n_splits = 3, shuffle = True, random_state = 6925), \n",
    "                           scoring=('precision', 'recall', 'f1'), return_train_score = False, n_jobs = -1)\n",
    "svc_fit_time_bush[j][0] = np.mean(svc_cv_result['fit_time'])\n",
    "svc_score_time_bush[j][0] = np.mean(svc_cv_result['score_time'])\n",
    "svc_test_f1_bush[j][0] = np.mean(svc_cv_result['test_f1'])\n",
    "svc_test_precision_bush[j][0] = np.mean(svc_cv_result['test_precision'])\n",
    "svc_test_recall_bush[j][0] = np.mean(svc_cv_result['test_recall'])\n",
    "    \n",
    "print(svc_test_f1_bush)\n",
    "print(svc_cv_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SVC for Williams\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2250, random_state = 6925)\n",
    "x_pca_svc_williams = pca.fit_transform(X)\n",
    "\n",
    "#C 1000 gamma 0.001,0.01,0.1\n",
    "svc_fit_time_williams = np.zeros((3,1))\n",
    "svc_score_time_williams = np.zeros((3,1))\n",
    "svc_test_f1_williams = np.zeros((3,1))\n",
    "svc_test_precision_williams = np.zeros((3,1))\n",
    "svc_test_recall_williams = np.zeros((3,1))\n",
    "j = 0\n",
    "svc_test_f1_williams[0][0] = 0\n",
    "\n",
    "svc = SVC(C = 1, kernel = 'sigmoid', gamma = 0.000244141)\n",
    "#svc = SVC(C = 100, kernel = 'linear', degree = 2, gamma = 0.001)\n",
    "svc = SVC(C = 1000, kernel = 'poly', degree = 15,gamma = 0.001,  coef0 = 200)\n",
    "svc_cv_result_williams = cross_validate(svc, x_pca_svc_williams, y_williams, cv = StratifiedKFold(n_splits = 3, shuffle = True, random_state = 6925), \n",
    "                           scoring=('precision', 'recall', 'f1'), return_train_score = False, n_jobs = -1)\n",
    "svc_fit_time_williams[j][0] = np.mean(svc_cv_result_williams['fit_time'])\n",
    "svc_score_time_williams[j][0] = np.mean(svc_cv_result_williams['score_time'])\n",
    "svc_test_f1_williams[j][0] = np.mean(svc_cv_result_williams['test_f1'])\n",
    "svc_test_precision_williams[j][0] = np.mean(svc_cv_result_williams['test_precision'])\n",
    "svc_test_recall_williams[j][0] = np.mean(svc_cv_result_williams['test_recall'])\n",
    "    \n",
    "print(svc_test_f1_williams)\n",
    "print(svc_cv_result_williams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# print(\"test_f1_bush: \", test_f1_bush)\n",
    "# print(\"test_f1_williams: \", test_f1_williams)\n",
    "# print(\"svc_test_f1_bush: \", svc_test_f1_bush[0][0])\n",
    "# print(\"svc_test_f1_williams: \", svc_test_f1_williams[0][0])\n",
    "\n",
    "\n",
    "# Once you run the code, it will generate a 'results.pkl' file. Do not modify the following code.\n",
    "#bush.pkl\n",
    "# test_f1_bush = np.zeros((3,1))\n",
    "# svc_test_f1_bush = np.zeros((3,1))\n",
    "# test_f1_williams = np.zeros((3,1))\n",
    "# svc_test_f1_williams = np.zeros((3,1))\n",
    "\n",
    "# test_f1_bush[0][0] = 0.14676116\n",
    "# test_f1_bush[1][0] = 0.07976078\n",
    "# test_f1_bush[2][0] = 0.039048693\n",
    "# svc_test_f1_bush[0][0] = 0.626287073\n",
    "\n",
    "bush = list()\n",
    "bush.append(test_f1_bush[0][0])\n",
    "# bush.append(test_f1_bush[1][0])\n",
    "# bush.append(test_f1_bush[2][0])\n",
    "bush.append(svc_test_f1_bush[0][0])\n",
    "\n",
    "pickle.dump((bush), open('bush.pkl', 'wb'))\n",
    "\n",
    "#williams.pkl\n",
    "# test_f1_williams[0][0] = 0.230716143\n",
    "# test_f1_williams[1][0] = 0.0\n",
    "# test_f1_williams[2][0] = 0.0\n",
    "# svc_test_f1_williams[0][0] = 0.482608697\n",
    "\n",
    "williams = list()\n",
    "williams.append(test_f1_williams[0][0])\n",
    "# williams.append(test_f1_williams[1][0])\n",
    "# williams.append(test_f1_williams[2][0])\n",
    "williams.append(svc_test_f1_williams[0][0])\n",
    "\n",
    "pickle.dump((williams), open('williams.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = pickle.load(open('bush.pkl', 'rb'))\n",
    "print(xs)\n",
    "\n",
    "xs = pickle.load(open('williams.pkl', 'rb'))\n",
    "print(xs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
